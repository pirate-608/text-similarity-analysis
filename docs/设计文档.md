# 设计文档

## 目标

- 基于词频向量的文本相似度计算，支持余弦、Jaccard 等指标。
- 面向批处理与交互式 CLI，便于快速对目录中的文本进行分析。
- 代码保持简洁、可扩展，便于添加新相似度算法或可视化方式。

## 架构概览

### 核心层 (C Language)
- `text_processor`：文本读取、分词、小写化、停用词过滤，输出 `Document`（包含词频哈希表）。
- `vector_math`：词频向量构建与相似度计算（余弦、Jaccard、距离类）。
- `file_manager`：目录扫描、文档集合管理、相似度矩阵生成与排序。
- `ui`：交互式菜单、热力图、统计输出。
- `main`：CLI 参数解析，分支到批处理或交互模式。

### 服务层 (Python Flask)
- `web/app.py`：Flask Web 应用入口，提供 RESTful API 和 HTML 页面。
- `web/core_bridge.py`：通过 `ctypes` 调用 C 核心库 (`libsimilarity.dll/so`)，实现高性能计算与 Python 灵活性的结合。
- `web/templates/index.html`：基于 Bootstrap 的前端界面，支持文件上传和结果可视化。

## 数据流

### CLI 模式
1) 读取目录中文件（`.txt`）→ 创建 `Document` → 读取全文 → 分词/过滤 → `HashTable` 存词频。
2) 构造文档集合 `DocumentCollection`。
3) 生成相似度矩阵 `SimilarityMatrix`（基于文档向量或词集）。
4) 可选输出：CSV、Top-N 相似对、ASCII 热力图、统计信息。

### Web 模式
1) 用户上传文件 → Flask 保存到临时目录。
2) Python 调用 C 动态库接口 `load_documents_from_dir` 处理临时目录。
3) C 核心计算相似度矩阵并返回指针。
4) Python 读取 C 结构体数据，转换为 JSON 格式返回前端。
5) 前端渲染 HTML 表格展示结果。

## 核心数据结构

- `HashTable`：链地址法，动态扩容，负载因子阈值 0.75。
- `Document`：`filename`、`HashTable *word_freq`、`word_count`。
- `DocumentCollection`：动态数组存放 `Document*`。
- `SimilarityMatrix`：二维 `double` 矩阵 + 文件名数组。
- `Vector`：动态 double 数组，支持扩容和归一化。

## 主要算法

- 分词：按字母和 `'` 作为单词字符，其余分隔；小写化后过滤停用词。
- 词频统计：哈希插入时累加频次；扩容时重哈希。
- 余弦相似度：构建并行词汇表向量，计算 `dot(v1,v2)/(||v1||·||v2||)`。
- Jaccard：基于哈希集合计算交集/并集规模。
- Top-N 相似对：枚举上三角，排序（`qsort`）后截断。

## 扩展与演进建议

- 增加 TF-IDF、BM25 等权重模型，提升语义区分度。
- 增加并行/批量计算（线程池或任务分片）以加速大目录处理。
- 增加文件编码探测与自动转码，提升跨平台健壮性。
- 提供可配置的分词规则与停用词来源（文件/在线）。
- 导出更多格式（JSON、Parquet），或提供 REST/gRPC 接口。

## 约束与兼容性

- 依赖 POSIX `dirent.h`；Windows 建议使用 MSYS2/MinGW 或 WSL。
- 单文件默认应小于内存可承受范围；哈希表初始容量可调。
- 未实现图形界面；`-g` 为占位。
